{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === CONFIG ===\n",
    "base_dir = \"uncentred_ternary_100_stratified4fold_1000per_seed3888 copy\"\n",
    "quadrants = [\"Q1\", \"Q2\", \"Q3\", \"Q4\"]\n",
    "img_size = (299, 299)\n",
    "batch_size = 32\n",
    "num_classes = 3\n",
    "epochs = 15\n",
    "\n",
    "# Create InceptionV3 model\n",
    "def create_inception_model(input_shape, num_classes):\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    base_model.trainable = False\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dropout(0.4)(x)\n",
    "    output = Dense(num_classes, activation='softmax')(x)\n",
    "    return Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# === 1. CROSS-VALIDATION ===\n",
    "best_model = None\n",
    "best_val_accuracy = 0  # Track the best validation accuracy\n",
    "\n",
    "fold_metrics = []\n",
    "\n",
    "for i in range(4):\n",
    "    test_q = quadrants[i]\n",
    "    train_qs = [q for j, q in enumerate(quadrants) if j != i]\n",
    "\n",
    "    print(f\"\\n==== Fold {i+1}: Test on {test_q}, Train on {train_qs} ====\")\n",
    "\n",
    "    # Data generators\n",
    "    datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    # Collect training data\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "    for q in train_qs:\n",
    "        train_gen = datagen.flow_from_directory(\n",
    "            directory=os.path.join(base_dir, q),\n",
    "            target_size=img_size,\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical',\n",
    "            shuffle=True\n",
    "        )\n",
    "\n",
    "        for x, y in train_gen:\n",
    "            train_data.append(x)\n",
    "            train_labels.append(y)\n",
    "\n",
    "    X_train = np.vstack(train_data)\n",
    "    y_train = np.vstack(train_labels)\n",
    "\n",
    "    # Test data generator\n",
    "    test_gen = datagen.flow_from_directory(\n",
    "        directory=os.path.join(base_dir, test_q),\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    # Create model\n",
    "    model = create_inception_model((*img_size, 3), num_classes)\n",
    "    model.compile(optimizer=Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Early stopping and checkpoint callback\n",
    "    es = EarlyStopping(patience=3, restore_best_weights=True, monitor='val_loss')\n",
    "    mc = ModelCheckpoint(f\"best_model_fold_{i+1}.h5\", save_best_only=True, monitor='val_loss')\n",
    "\n",
    "    # Training the model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=epochs,\n",
    "        validation_split=0.1,\n",
    "        callbacks=[es, mc],\n",
    "        batch_size=32,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Evaluation on test set\n",
    "    preds = model.predict(test_gen, verbose=0)\n",
    "    y_true = test_gen.classes\n",
    "    y_pred = np.argmax(preds, axis=1)\n",
    "\n",
    "    print(f\"Classification Report for Fold {i+1}:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "    # Track best model based on validation accuracy\n",
    "    val_accuracy = max(history.history['val_accuracy'])\n",
    "    fold_metrics.append(val_accuracy)\n",
    "\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        best_model = model  # Save the model with the best validation accuracy\n",
    "\n",
    "# === 2. PRINT CROSS-VAL RESULTS ===\n",
    "print(\"\\n==== Cross-Validation Accuracy Scores ====\")\n",
    "for i, score in enumerate(fold_metrics):\n",
    "    print(f\"Fold {i+1}: {score:.4f}\")\n",
    "print(f\"Average Accuracy: {np.mean(fold_metrics):.4f}\")\n",
    "\n",
    "# === 3. SAVE THE BEST MODEL ===\n",
    "if best_model:\n",
    "    best_model.save(\"best_inception_model_across_folds.h5\")\n",
    "    print(\"\\n✅ Best model across all folds saved as 'best_inception_model_across_folds.h5'.\")\n",
    "\n",
    "# === 4. FINAL TRAINING ON ALL DATA ===\n",
    "print(\"\\n==== Training Final Model on ALL Data ====\")\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "all_data = []\n",
    "all_labels = []\n",
    "\n",
    "# Collect all data for final training\n",
    "for q in quadrants:\n",
    "    temp_gen = train_datagen.flow_from_directory(\n",
    "        directory=os.path.join(base_dir, q),\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True\n",
    "    )\n",
    "    for x, y in temp_gen:\n",
    "        all_data.append(x)\n",
    "        all_labels.append(y)\n",
    "\n",
    "X_final = np.vstack(all_data)\n",
    "y_final = np.vstack(all_labels)\n",
    "\n",
    "# Final model creation\n",
    "final_model = create_inception_model((*img_size, 3), num_classes)\n",
    "final_model.compile(optimizer=Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train final model\n",
    "history = final_model.fit(\n",
    "    X_final, y_final,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.1,\n",
    "    batch_size=32,\n",
    "    callbacks=[EarlyStopping(patience=5, restore_best_weights=True, monitor='val_loss')],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# === 5. SAVE FINAL MODEL ===\n",
    "final_model.save(\"final_model_inception.h5\")\n",
    "print(\"\\n✅ Final model saved as 'inal_model_inception.h5'.\")\n",
    "\n",
    "# === 6. PLOT TRAINING HISTORY ===\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "plt.title(\"Final Model Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title(\"Final Model Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"final_training_plot.png\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "r-tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
