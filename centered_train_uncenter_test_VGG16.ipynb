{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0912e691-df92-4c2b-b799-5d6f95c51f22",
   "metadata": {},
   "source": [
    "## load the dataset and create the final using dataset with attribute \"Quadrant\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3097a1f2-946e-42a9-9a4a-56da65fbe3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "train_folder_Q1 = Path(\"projectdata/images/100_stratified4fold_1000per_seed3888/Q1\")\n",
    "train_folder_Q2= Path(\"projectdata/images/100_stratified4fold_1000per_seed3888/Q2\")\n",
    "train_folder_Q3 = Path(\"projectdata/images/100_stratified4fold_1000per_seed3888/Q3\")\n",
    "train_folder_Q4 = Path(\"projectdata/images/100_stratified4fold_1000per_seed3888/Q4\")\n",
    "\n",
    "test_folder_Q1 = Path(\"projectdata/images/uncentred_ternary_100_stratified4fold_1000per_seed3888/Q1\")\n",
    "test_folder_Q2 = Path(\"projectdata/images/uncentred_ternary_100_stratified4fold_1000per_seed3888/Q2\")\n",
    "test_folder_Q3 = Path(\"projectdata/images/uncentred_ternary_100_stratified4fold_1000per_seed3888/Q3\")\n",
    "test_folder_Q4 = Path(\"projectdata/images/uncentred_ternary_100_stratified4fold_1000per_seed3888/Q4\")\n",
    "\n",
    "cell_types = [\"Empty\", \"Non-Tumor\", \"Tumor\"]\n",
    "# multiclass_folder = Path(\"projectdata/images/uncentred_multiclass_224_stratified4fold_1000per_seed3888\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f665fc11-8efd-41b6-9c33-96420de4b37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a list for all records\n",
    "records = []\n",
    "  \n",
    "# Traverse folders\n",
    "def get_records(quadrant, path, test):\n",
    "    records = []\n",
    "    \n",
    "    for folder_name in os.listdir(path):\n",
    "        folder_path = Path(f\"{path}/{folder_name}\")\n",
    "        if folder_path.is_dir():\n",
    "            \n",
    "            if folder_name not in cell_types:\n",
    "                print(f\"Warning: Folder {folder_name} not found in cell types. Skipping.\")\n",
    "                continue\n",
    "    \n",
    "            # Loop through images\n",
    "            for file_name in os.listdir(folder_path):\n",
    "                if file_name.endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "                    full_path = f\"{folder_path}/{file_name}\"\n",
    "                    parts = file_name.replace(\".png\", \"\").split(\"_\")\n",
    "\n",
    "                    if test:\n",
    "                        x = int(parts[1])\n",
    "                        y = int(parts[2])\n",
    "                    else:\n",
    "                        x = None\n",
    "                        y = None\n",
    "    \n",
    "                    records.append({\n",
    "                        \"Quadrant\": quadrant,\n",
    "                        \"File Name\": file_name,\n",
    "                        \"Path\": str(full_path),\n",
    "                        \"Category Type\": folder_name,\n",
    "                        \"x\":x,\n",
    "                        \"y\":y\n",
    "                    })\n",
    "    return records\n",
    "\n",
    "train_records_q1 = get_records(\"Q1\", train_folder_Q1, False)\n",
    "train_records_q2 = get_records(\"Q2\", train_folder_Q2, False)\n",
    "train_records_q3 = get_records(\"Q3\", train_folder_Q3, False)\n",
    "train_records_q4 = get_records(\"Q4\", train_folder_Q4, False)\n",
    "\n",
    "train_df_q1 = pd.DataFrame(train_records_q1)\n",
    "train_df_q2 = pd.DataFrame(train_records_q2)\n",
    "train_df_q3 = pd.DataFrame(train_records_q3)\n",
    "train_df_q4 = pd.DataFrame(train_records_q4)\n",
    "\n",
    "test_records_q1 = get_records(\"Q1\", test_folder_Q1, True)\n",
    "test_records_q2 = get_records(\"Q2\", test_folder_Q2, True)\n",
    "test_records_q3 = get_records(\"Q3\", test_folder_Q3, True)\n",
    "test_records_q4 = get_records(\"Q4\", test_folder_Q4, True)\n",
    "\n",
    "test_df_q1 = pd.DataFrame(test_records_q1)\n",
    "test_df_q2 = pd.DataFrame(test_records_q2)\n",
    "test_df_q3 = pd.DataFrame(test_records_q3)\n",
    "test_df_q4 = pd.DataFrame(test_records_q4)\n",
    "\n",
    "# # Create DataFrame\n",
    "# df_image_raw = pd.DataFrame(records)\n",
    "# df_image_raw.head()\n",
    "\n",
    "# df_image = df_image_raw[df_image_raw['Category Type'] != \"Unlabeled\"].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4eba60a-e67c-4aee-833a-a81d836689cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_final = pd.concat([train_df_q1, train_df_q2, train_df_q3, train_df_q4])\n",
    "test_df_final = pd.concat([test_df_q1, test_df_q2, test_df_q3, test_df_q4])\n",
    "# df_final.to_csv(\"used_dataset_bindy.csv\", index=False)\n",
    "df_g_tr = train_df_final.groupby(\"Category Type\")[\"File Name\"].count()\n",
    "df_g_te = test_df_final.groupby(\"Category Type\")[\"File Name\"].count()\n",
    "df_g2_tr = train_df_final.groupby(\"Quadrant\")[\"Category Type\"].count()\n",
    "df_g2_te = test_df_final.groupby(\"Quadrant\")[\"Category Type\"].count()\n",
    "# df_g_tr\n",
    "# df_g_te\n",
    "# test_df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a4f11f3-b0a9-4159-bc39-c29d072363e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category Type\n",
       "Empty         400\n",
       "Non-Tumor    2012\n",
       "Tumor        1834\n",
       "Name: File Name, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_g_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea7306ee-158e-4757-92c2-a0eaf1a72119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Quadrant\n",
       "Q1    1050\n",
       "Q2     990\n",
       "Q3    1103\n",
       "Q4    1103\n",
       "Name: Category Type, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_g2_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "348f99bd-35a5-4729-9632-4b47ea5189dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category Type\n",
       "Empty         512\n",
       "Non-Tumor    2000\n",
       "Tumor        2000\n",
       "Name: File Name, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_g_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3bcd063-4163-4f9c-9fb6-776320c9cbfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Quadrant\n",
       "Q1    1128\n",
       "Q2    1128\n",
       "Q3    1128\n",
       "Q4    1128\n",
       "Name: Category Type, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_g2_te"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37050dc0-e8db-412c-8b8c-61d4bf112d1a",
   "metadata": {},
   "source": [
    "## Implementing the VGG16 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81e5da92-2cbf-4f1d-941f-91b31fb10798",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(3888)\n",
    "tf.random.set_seed(3888)\n",
    "\n",
    "# # Load your balanced dataset\n",
    "# df = df_final\n",
    "\n",
    "# # Print basic info\n",
    "# print(df['Category Type'].value_counts())\n",
    "# print(df['Quadrant'].value_counts())\n",
    "\n",
    "label_map = {'Tumor': 0, 'Non-Tumor': 1, 'Empty': 2}\n",
    "\n",
    "train_df_final['label'] = train_df_final['Category Type'].map(label_map)\n",
    "train_df_final['label'] = train_df_final['label'].astype(str)\n",
    "\n",
    "test_df_final['label'] = test_df_final['Category Type'].map(label_map)\n",
    "test_df_final['label'] = test_df_final['label'].astype(str)\n",
    "\n",
    "def build_vgg16_model(input_shape=(224, 224, 3)):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False  # Freeze base layers\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(3, activation='softmax')(x)  # 3 classes\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6074d4fa-1a01-413f-bfda-e34db460d718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quadrant</th>\n",
       "      <th>File Name</th>\n",
       "      <th>Path</th>\n",
       "      <th>Category Type</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1</td>\n",
       "      <td>topleft_9_0.png</td>\n",
       "      <td>projectdata/images/100_stratified4fold_1000per...</td>\n",
       "      <td>Empty</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q1</td>\n",
       "      <td>topleft_1_9.png</td>\n",
       "      <td>projectdata/images/100_stratified4fold_1000per...</td>\n",
       "      <td>Empty</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q1</td>\n",
       "      <td>topleft_1_8.png</td>\n",
       "      <td>projectdata/images/100_stratified4fold_1000per...</td>\n",
       "      <td>Empty</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q1</td>\n",
       "      <td>topleft_9_1.png</td>\n",
       "      <td>projectdata/images/100_stratified4fold_1000per...</td>\n",
       "      <td>Empty</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q1</td>\n",
       "      <td>topleft_9_3.png</td>\n",
       "      <td>projectdata/images/100_stratified4fold_1000per...</td>\n",
       "      <td>Empty</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>Q1</td>\n",
       "      <td>cell_33431_100.png</td>\n",
       "      <td>projectdata/images/100_stratified4fold_1000per...</td>\n",
       "      <td>Non-Tumor</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>Q1</td>\n",
       "      <td>cell_98512_100.png</td>\n",
       "      <td>projectdata/images/100_stratified4fold_1000per...</td>\n",
       "      <td>Non-Tumor</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>Q1</td>\n",
       "      <td>cell_97789_100.png</td>\n",
       "      <td>projectdata/images/100_stratified4fold_1000per...</td>\n",
       "      <td>Non-Tumor</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>Q1</td>\n",
       "      <td>cell_61222_100.png</td>\n",
       "      <td>projectdata/images/100_stratified4fold_1000per...</td>\n",
       "      <td>Non-Tumor</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>Q1</td>\n",
       "      <td>cell_34095_100.png</td>\n",
       "      <td>projectdata/images/100_stratified4fold_1000per...</td>\n",
       "      <td>Non-Tumor</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1050 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Quadrant           File Name  \\\n",
       "0          Q1     topleft_9_0.png   \n",
       "1          Q1     topleft_1_9.png   \n",
       "2          Q1     topleft_1_8.png   \n",
       "3          Q1     topleft_9_1.png   \n",
       "4          Q1     topleft_9_3.png   \n",
       "...       ...                 ...   \n",
       "1045       Q1  cell_33431_100.png   \n",
       "1046       Q1  cell_98512_100.png   \n",
       "1047       Q1  cell_97789_100.png   \n",
       "1048       Q1  cell_61222_100.png   \n",
       "1049       Q1  cell_34095_100.png   \n",
       "\n",
       "                                                   Path Category Type     x  \\\n",
       "0     projectdata/images/100_stratified4fold_1000per...         Empty  None   \n",
       "1     projectdata/images/100_stratified4fold_1000per...         Empty  None   \n",
       "2     projectdata/images/100_stratified4fold_1000per...         Empty  None   \n",
       "3     projectdata/images/100_stratified4fold_1000per...         Empty  None   \n",
       "4     projectdata/images/100_stratified4fold_1000per...         Empty  None   \n",
       "...                                                 ...           ...   ...   \n",
       "1045  projectdata/images/100_stratified4fold_1000per...     Non-Tumor  None   \n",
       "1046  projectdata/images/100_stratified4fold_1000per...     Non-Tumor  None   \n",
       "1047  projectdata/images/100_stratified4fold_1000per...     Non-Tumor  None   \n",
       "1048  projectdata/images/100_stratified4fold_1000per...     Non-Tumor  None   \n",
       "1049  projectdata/images/100_stratified4fold_1000per...     Non-Tumor  None   \n",
       "\n",
       "         y label  \n",
       "0     None     2  \n",
       "1     None     2  \n",
       "2     None     2  \n",
       "3     None     2  \n",
       "4     None     2  \n",
       "...    ...   ...  \n",
       "1045  None     1  \n",
       "1046  None     1  \n",
       "1047  None     1  \n",
       "1048  None     1  \n",
       "1049  None     1  \n",
       "\n",
       "[1050 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df_final[train_df_final[\"Quadrant\"] == \"Q1\"]\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ab7d360d-458f-49fb-ae69-77460fc9f3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Fold: Test on Q1\n",
      "Found 1050 validated image filenames belonging to 3 classes.\n",
      "Found 3196 validated image filenames belonging to 3 classes.\n",
      "Found 1128 validated image filenames belonging to 3 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m533s\u001b[0m 17s/step - accuracy: 0.4043 - loss: 1.0751 - val_accuracy: 0.4928 - val_loss: 0.7759\n",
      "Epoch 2/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.5306 - loss: 0.8183"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 80\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[1;32m     78\u001b[0m early_stop \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 80\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m     81\u001b[0m     train_gen,\n\u001b[1;32m     82\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mval_gen,\n\u001b[1;32m     83\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m     84\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[early_stop],\n\u001b[1;32m     85\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     86\u001b[0m )\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# --- Plot training curves ---\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# Accuracy\u001b[39;00m\n\u001b[1;32m     93\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m5\u001b[39m))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:395\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_epoch_iterator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_epoch_iterator \u001b[38;5;241m=\u001b[39m TFEpochIterator(\n\u001b[1;32m    386\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[1;32m    387\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    394\u001b[0m     )\n\u001b[0;32m--> 395\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate(\n\u001b[1;32m    396\u001b[0m     x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[1;32m    397\u001b[0m     y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[1;32m    398\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39mval_sample_weight,\n\u001b[1;32m    399\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mvalidation_batch_size \u001b[38;5;129;01mor\u001b[39;00m batch_size,\n\u001b[1;32m    400\u001b[0m     steps\u001b[38;5;241m=\u001b[39mvalidation_steps,\n\u001b[1;32m    401\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[1;32m    402\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    403\u001b[0m     _use_cached_eval_dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    404\u001b[0m )\n\u001b[1;32m    405\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    407\u001b[0m }\n\u001b[1;32m    408\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:483\u001b[0m, in \u001b[0;36mTensorFlowTrainer.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    482\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m--> 483\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_function(iterator)\n\u001b[1;32m    484\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_end(step, logs)\n\u001b[1;32m    485\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_evaluating:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:219\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    217\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    218\u001b[0m     ):\n\u001b[0;32m--> 219\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m multi_step_on_iterator(iterator)\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[1;32m    221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[1;32m    880\u001b[0m )\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1688\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1688\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m   1689\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1690\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   1691\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1692\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[1;32m   1693\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1694\u001b[0m   )\n\u001b[1;32m   1695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1696\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1697\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1698\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1702\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1703\u001b[0m   )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(3888)\n",
    "tf.random.set_seed(3888)\n",
    "\n",
    "# Prepare ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "quadrants = [\"Q1\", \"Q2\", \"Q3\", \"Q4\"]\n",
    "\n",
    "# Store results\n",
    "fold_accuracies = []\n",
    "fold_f1_scores = []\n",
    "fold_reports = []\n",
    "models = {}\n",
    "\n",
    "for quadrant in quadrants:\n",
    "    print(f\"Starting Fold: Test on {quadrant}\")\n",
    "\n",
    "    # Split\n",
    "    train_df = train_df_final[train_df_final[\"Quadrant\"] == quadrant]\n",
    "    val_df = train_df_final[train_df_final[\"Quadrant\"] != quadrant]\n",
    "    test_df = test_df_final[test_df_final[\"Quadrant\"] == quadrant]\n",
    "\n",
    "    # # Further split train/val internally\n",
    "    # train_df, val_df = train_test_split(\n",
    "    #     train_val_df, \n",
    "    #     test_size=0.2, \n",
    "    #     stratify=train_val_df['label'], \n",
    "    #     random_state=3888\n",
    "    # )\n",
    "\n",
    "    # Data Generators\n",
    "    train_gen = train_datagen.flow_from_dataframe(\n",
    "        train_df,\n",
    "        x_col='Path',\n",
    "        y_col='label',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    val_gen = val_test_datagen.flow_from_dataframe(\n",
    "        val_df,\n",
    "        x_col='Path',\n",
    "        y_col='label',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    test_gen = val_test_datagen.flow_from_dataframe(\n",
    "        test_df,\n",
    "        x_col='Path',\n",
    "        y_col='label',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    # Build Model\n",
    "    model = build_vgg16_model()\n",
    "\n",
    "    # Train\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(\n",
    "        train_gen,\n",
    "        validation_data=val_gen,\n",
    "        epochs=20,\n",
    "        callbacks=[early_stop],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Evaluate\n",
    "\n",
    "    # --- Plot training curves ---\n",
    "    \n",
    "    # Accuracy\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy', marker='o')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy', marker='o')\n",
    "    plt.title(f'Fold {quadrant} Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "    # Loss\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(history.history['loss'], label='Train Loss', marker='o')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss', marker='o')\n",
    "    plt.title(f'Fold {quadrant} Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "    # --- Save model ---\n",
    "    model.save(f\"vgg16_fold_{quadrant}.h5\")\n",
    "    \n",
    "    models[quadrant] = model\n",
    "    \n",
    "    print(f\"Saved model: vgg16_fold_{quadrant}.h5\")\n",
    "    \n",
    "    # --- Confusion Matrix on Test Set ---\n",
    "    y_true = test_gen.classes\n",
    "    y_pred_probs = model.predict(test_gen)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Tumor\", \"Non-Tumor\", \"Empty\"])\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(f'Fold {quadrant} Confusion Matrix (test on uncentred)')\n",
    "    plt.show()\n",
    "\n",
    "    acc = np.mean(y_true == y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    print(f\"Fold {quadrant} Accuracy: {acc:.4f}, F1 Score: {f1:.4f}\")\n",
    "\n",
    "    fold_accuracies.append(acc)\n",
    "    fold_f1_scores.append(f1)\n",
    "\n",
    "    # --- Classification Report ---\n",
    "    report = classification_report(\n",
    "    y_true, \n",
    "    y_pred, \n",
    "    target_names=[\"Tumor\", \"Non-Tumor\", \"Empty\"],\n",
    "    digits=4\n",
    "    )\n",
    "    fold_reports.append(report)\n",
    "    print(f\"Classification Report for Fold {quadrant}:\\n{report}\")\n",
    "\n",
    "# Final report\n",
    "mean_acc = np.mean(fold_accuracies)\n",
    "mean_f1 = np.mean(fold_f1_scores)\n",
    "print(f\"Average 4-Fold Test Accuracy: {mean_acc:.4f}\")\n",
    "print(f\"Average 4-Fold Test f1: {mean_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "43ae51d0-e8b4-4c77-9cfb-d872dc121989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Model using Q1: 0.4287878787878788\n",
      "F1 Score of Model using Q1: 0.3395456993273604\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy of Model: {fold_accuracies}\")\n",
    "print(f\"F1 Score of Model: {fold_f1_scores}\")\n",
    "# print(f\"Accuracy of Model using Q2: {fold_accuracies[1]}\")\n",
    "# print(f\"Accuracy of Model using Q3: {fold_accuracies[2]}\")\n",
    "# print(f\"Accuracy of Model using Q4: {fold_accuracies[3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9828fea8-65b3-4d4f-8f83-7d65a35b0330",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = [\"Q1\", \"Q2\", \"Q3\", \"Q4\"] \n",
    "\n",
    "x = np.arange(len(folds))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 5))\n",
    "\n",
    "rects1 = ax.bar(x - width/2, fold_accuracies, width, label='Accuracy', color='skyblue')\n",
    "rects2 = ax.bar(x + width/2, fold_f1_scores, width, label='F1 Score', color='lightcoral')\n",
    "\n",
    "# Labels and formatting\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_xlabel('Fold (Quadrant)')\n",
    "ax.set_title('Model Accuracy and F1 Score Across Folds')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(folds)\n",
    "ax.set_ylim(0, 1.1)\n",
    "ax.legend()\n",
    "\n",
    "# Annotate each bar\n",
    "for rects in [rects1, rects2]:\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate(f'{height:.2f}',\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 4),\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff5aab9-b8aa-4d14-a73e-b8cfb16e356f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import pandas as pd\n",
    "# from PIL import Image\n",
    "# import matplotlib.patches as patches\n",
    "# from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "# import seaborn as sns\n",
    "\n",
    "# Image.MAX_IMAGE_PIXELS = None\n",
    "\n",
    "# # CONFIG\n",
    "# IMAGE_SIZE = (224, 224)\n",
    "# PATCH_SIZE = 224  # should match IMAGE_SIZE\n",
    "# STRIDE = 224  # adjust stride for overlapping or non-overlapping\n",
    "# CLASS_COLORS = {'Tumor': 0, 'Non-Tumor': 1, 'Empty': 2}\n",
    "# COLOR_MAP = {0: 'blue', 1: 'green', 2: 'red'}\n",
    "\n",
    "# # Load the big image\n",
    "# big_img = Image.open('BigImage.tif').convert('RGB')\n",
    "# big_arr = np.array(big_img)\n",
    "# h, w, _ = big_arr.shape\n",
    "\n",
    "# # model_input = preprocess_input  \n",
    "\n",
    "# # Load best-performing model\n",
    "# # folds = [\"Q1\", \"Q2\", \"Q3\", \"Q4\"]\n",
    "# # best_fold = folds[np.argmax(fold_f1_scores)]\n",
    "# best_fold = \"Q1\"\n",
    "# best_model_path = f\"vgg16_fold_{best_fold}.h5\"\n",
    "# model = tf.keras.models.load_model(best_model_path)\n",
    "# print(f\"Using best model from fold {best_fold}\")\n",
    "\n",
    "# # ---------------- HEATMAP INFERENCE ----------------\n",
    "# heatmap = np.zeros((h // STRIDE, w // STRIDE), dtype=int)\n",
    "\n",
    "# for i_idx, i in enumerate(range(0, h - PATCH_SIZE + 1, STRIDE)):\n",
    "#     for j_idx, j in enumerate(range(0, w - PATCH_SIZE + 1, STRIDE)):\n",
    "#         patch = big_arr[i:i+PATCH_SIZE, j:j+PATCH_SIZE]\n",
    "#         patch_resized = cv2.resize(patch, IMAGE_SIZE).astype(np.float32)\n",
    "#         patch_input = preprocess_input(np.expand_dims(patch_resized, axis=0))  # for VGG16\n",
    "#         pred = model.predict(patch_input, verbose=0)\n",
    "#         label = np.argmax(pred)\n",
    "#         heatmap[i_idx, j_idx] = label\n",
    "\n",
    "# # ---------------- PLOT HEATMAP ----------------\n",
    "# plt.figure(figsize=(12, 10))\n",
    "# sns.heatmap(heatmap, cmap='coolwarm', cbar_kws={'ticks': [0, 1, 2]},\n",
    "#             xticklabels=False, yticklabels=False)\n",
    "# plt.title(f'Prediction Heatmap using Fold {best_fold} Model')\n",
    "# cbar = plt.gca().collections[0].colorbar\n",
    "# cbar.set_ticklabels(CLASS_LABELS)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c235e1ff-b0d9-4652-adfc-7b55c4c4009e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# plt.figure(figsize=(12, 10))\n",
    "# sns.heatmap(heatmap, cmap='coolwarm', cbar_kws={'ticks': [0, 1, 2]},\n",
    "#             xticklabels=False, yticklabels=False)\n",
    "# plt.title(f'Prediction Heatmap using Fold {best_fold} Model')\n",
    "# cbar = plt.gca().collections[0].colorbar\n",
    "# cbar.set_ticklabels(cell_types)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830b67d2-cd8d-4201-8d5e-bc10fe782d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df_final\n",
    "# tumor_coords = []\n",
    "\n",
    "# for col in df.columns:\n",
    "#     if 'x' in col:\n",
    "#         y_col = col.replace('x', 'y')\n",
    "#         xs = df[col].dropna()\n",
    "#         ys = df[y_col].dropna()\n",
    "#         tumor_coords.extend(zip(xs.astype(int), ys.astype(int)))\n",
    "\n",
    "# # Build ground truth grid\n",
    "# gt_map = np.zeros_like(heatmap)\n",
    "\n",
    "# for x, y in tumor_coords:\n",
    "#     if x < w and y < h:\n",
    "#         i = y // STRIDE\n",
    "#         j = x // STRIDE\n",
    "#         if i < gt_map.shape[0] and j < gt_map.shape[1]:\n",
    "#             gt_map[i, j] = 2  # mark as tumor\n",
    "\n",
    "# # Plot heatmap with overlay\n",
    "# plt.figure(figsize=(12, 10))\n",
    "# sns.heatmap(heatmap, cmap='coolwarm', xticklabels=False, yticklabels=False, cbar=False)\n",
    "# plt.title('Prediction Heatmap with Ground Truth Overlay')\n",
    "\n",
    "# # Overlay ground truth (tumor) cells\n",
    "# for i in range(gt_map.shape[0]):\n",
    "#     for j in range(gt_map.shape[1]):\n",
    "#         if gt_map[i, j] == 2:\n",
    "#             plt.gca().add_patch(patches.Rectangle((j, i), 1, 1, edgecolor='yellow', fill=False, linewidth=1))\n",
    "\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
